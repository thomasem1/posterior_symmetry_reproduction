{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Symmetry Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\dev\\school\\DD2412 DLA\\posterior_symmetry_reproduction\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR, LambdaLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_uncertainty import TUTrainer\n",
    "from torch_uncertainty.datamodules import MNISTDataModule\n",
    "from torch_uncertainty.losses import ELBOLoss\n",
    "from torch_uncertainty.models.lenet import bayesian_lenet, lenet\n",
    "from torch_uncertainty.models import mc_dropout\n",
    "from torch_uncertainty.routines import ClassificationRoutine\n",
    "from lightning.pytorch import LightningModule\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, accuracy_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "from laplace import Laplace\n",
    "from utils.swa_gaussian.swag.posteriors import SWAG\n",
    "from torch_uncertainty.models import SWAG as TUSWAG\n",
    "import utils.swa_gaussian.swag.posteriors as swag_posteriors\n",
    "from utils.posterior_symmetry.mmd.mmd_torch import mmdagg\n",
    "from utils.posterior_symmetry.symmetries.permutation import Permuter\n",
    "from utils.posterior_symmetry.symmetries.scale import Scaler\n",
    "from utils.bayes_neural_networks.src.Stochastic_Gradient_HMC_SA.optimizers import H_SA_SGHMC\n",
    "\n",
    "from pathlib import Path\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_PATH = \"data\"\n",
    "MODEL_PATH = Path(\"models\", \"trained_optunets\")\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Parameters from paper\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.04\n",
    "WEIGHT_DECAY = 2e-4\n",
    "\n",
    "## Method params\n",
    "DROPOUT_RATE = 0.2 # last layer dropout rate\n",
    "\n",
    "# Models\n",
    "NMODELS = 100\n",
    "ENSEMBLE_MODELS = 10 # number of models to use in ensemble\n",
    "N_SAMPLES = 100 # number of samples to draw from model\n",
    "\n",
    "MC_SAMPLES = 3 # Posterior samples for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "root = Path(DATA_PATH)\n",
    "datamodule = MNISTDataModule(root=root, batch_size=BATCH_SIZE, eval_ood=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OptuNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Add layers for OptuNet (use Section C.2.1 from the paper for details)\n",
    "        # Layers: Conv2D (out_ch=2, ks=4, groups=1) -> Max Pooling (ks=3, stride=3) -> ReLU -> Conv2D (out_ch=10, ks=5, groups=2) -> Average Pooling -> ReLU -> Linear 10x10\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=4, groups=1, bias=False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=10, kernel_size=5, groups=2, bias=False)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.pool1(self.conv1(x)))  # First conv, max pooling, ReLU\n",
    "        x = self.relu(self.pool2(self.conv2(x)))  # Second conv, avg pooling, ReLU\n",
    "        x = torch.mean(x, dim=(2, 3))\n",
    "        x = self.fc1(x)  # Linear layer\n",
    "        return x\n",
    "\n",
    "# Optimizer and LR scheduler\n",
    "def optim_optunet(model: nn.Module):\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[15, 30],\n",
    "        gamma=0.5\n",
    "    )\n",
    "    return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "def optim_cosine_optunet(model: nn.Module, warmup_steps=5, total_steps=60, min_lr=0, max_lr=0.04):\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_steps:\n",
    "            # Linear warmup: Increase from 0 to max_lr\n",
    "            return float(epoch) / float(max(1, warmup_steps))\n",
    "        else:\n",
    "            # Cosine decay after warmup\n",
    "            progress = (epoch - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "            return min_lr + 0.5 * (max_lr - min_lr) * (1 + torch.cos(torch.pi * progress))\n",
    "\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "# Loss function\n",
    "def loss_optunet(model: nn.Module):\n",
    "    loss = ELBOLoss(\n",
    "        model=model,\n",
    "        inner_loss=nn.CrossEntropyLoss(),\n",
    "        kl_weight= 1/10000,\n",
    "        num_samples=3,\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions\n",
    "def load_optunet_model(version: int):\n",
    "    model = OptuNet()\n",
    "    path = Path(f\"models/mnist-optunet-0-8191/version_{version}.safetensors\")\n",
    "\n",
    "    if not path.exists():\n",
    "        raise ValueError(\"File does not exist\")\n",
    "\n",
    "    state_dict = load_file(path)\n",
    "    model.load_state_dict(state_dict=state_dict)\n",
    "    return model\n",
    "\n",
    "def load_trained_optunet(path):\n",
    "    checkpoint = torch.load(path)\n",
    "\n",
    "    # Filter out unwanted keys (e.g., those related to loss)\n",
    "    state_dict = {\n",
    "        k.replace(\"model.\", \"\"): v\n",
    "        for k, v in checkpoint[\"state_dict\"].items()\n",
    "        if not k.startswith(\"loss.\")\n",
    "    }\n",
    "    model = OptuNet()\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_optunets(n_models = 100, start_idx = 0, tag=\"\"):\n",
    "    # tag (str) is used to tag save name with specific tag\n",
    "\n",
    "    # Train n_models OptuNets\n",
    "    for i in range(start_idx, n_models):\n",
    "        model = OptuNet()\n",
    "\n",
    "        trainer = TUTrainer(\n",
    "            accelerator=\"gpu\",\n",
    "            enable_progress_bar=False,\n",
    "            max_epochs=EPOCHS)\n",
    "        \n",
    "        # loss\n",
    "        loss = ELBOLoss(\n",
    "            model=model,\n",
    "            inner_loss=nn.CrossEntropyLoss(),\n",
    "            kl_weight=1/10000,\n",
    "            num_samples=3,\n",
    "        )\n",
    "\n",
    "        routine = ClassificationRoutine(\n",
    "            model=model,\n",
    "            num_classes=datamodule.num_classes,\n",
    "            loss=loss,\n",
    "            optim_recipe=optim_optunet(model),\n",
    "            is_ensemble=True\n",
    "        )\n",
    "\n",
    "        trainer.fit(model=routine, datamodule=datamodule)\n",
    "\n",
    "        # Save the trained model\n",
    "        save_path = Path(MODEL_PATH, f\"model_{tag}{i}.pt\")\n",
    "        trainer.save_checkpoint(save_path)\n",
    "    \n",
    "    print(f\"Trained {n_models} models. Saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_optunets(n_models=NMODELS, start_idx=30, tag=\"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(model, path):\n",
    "    # Ensure path exists\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models(n_models = 100, start_idx = 0, tag=\"\"):\n",
    "    posterior_models = []\n",
    "\n",
    "    for i in range(start_idx, n_models):\n",
    "        path = Path(MODEL_PATH, f\"model_{tag}{i}.pt\")\n",
    "        model = load_trained_optunet(path)\n",
    "        model = model.to(DEVICE) # Needed?\n",
    "        posterior_models.append(model)\n",
    "    \n",
    "    print(f\"Loaded {len(posterior_models)} models\")\n",
    "    return posterior_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_31292\\3394468100.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 31 models\n"
     ]
    }
   ],
   "source": [
    "posterior_models = load_trained_models(n_models=31, tag=\"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptuDrop(OptuNet):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(super().forward(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model            | OptuDrop         | 392    | train\n",
      "1 | loss             | CrossEntropyLoss | 0      | train\n",
      "2 | format_batch_fn  | Identity         | 0      | train\n",
      "3 | val_cls_metrics  | MetricCollection | 0      | train\n",
      "4 | test_cls_metrics | MetricCollection | 0      | train\n",
      "5 | test_id_entropy  | Entropy          | 0      | train\n",
      "6 | mixup            | Identity         | 0      | train\n",
      "--------------------------------------------------------------\n",
      "392       Trainable params\n",
      "0         Non-trainable params\n",
      "392       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 938/938 [00:09<00:00, 94.13it/s, v_num=106, train_loss=1.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [00:05<00:00, 163.68it/s, v_num=106, train_loss=1.650, Acc%=41.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [00:06<00:00, 154.54it/s, v_num=106, train_loss=1.680, Acc%=48.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 938/938 [00:06<00:00, 147.46it/s, v_num=106, train_loss=1.620, Acc%=65.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 938/938 [00:05<00:00, 157.83it/s, v_num=106, train_loss=1.710, Acc%=67.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [00:05<00:00, 164.73it/s, v_num=106, train_loss=1.250, Acc%=65.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 938/938 [00:05<00:00, 158.81it/s, v_num=106, train_loss=1.640, Acc%=71.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 938/938 [00:05<00:00, 160.11it/s, v_num=106, train_loss=1.310, Acc%=68.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 938/938 [00:06<00:00, 151.05it/s, v_num=106, train_loss=1.070, Acc%=71.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 938/938 [00:06<00:00, 143.31it/s, v_num=106, train_loss=1.230, Acc%=74.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 938/938 [00:05<00:00, 159.40it/s, v_num=106, train_loss=1.050, Acc%=72.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 938/938 [00:05<00:00, 162.21it/s, v_num=106, train_loss=1.260, Acc%=76.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 938/938 [00:06<00:00, 144.78it/s, v_num=106, train_loss=1.490, Acc%=68.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 938/938 [00:06<00:00, 142.87it/s, v_num=106, train_loss=0.844, Acc%=75.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 938/938 [00:06<00:00, 151.33it/s, v_num=106, train_loss=0.933, Acc%=74.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 938/938 [00:06<00:00, 153.40it/s, v_num=106, train_loss=1.250, Acc%=73.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 938/938 [00:06<00:00, 148.41it/s, v_num=106, train_loss=1.200, Acc%=77.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 938/938 [00:06<00:00, 144.26it/s, v_num=106, train_loss=1.040, Acc%=76.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 938/938 [00:06<00:00, 150.53it/s, v_num=106, train_loss=1.030, Acc%=77.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 938/938 [00:06<00:00, 145.90it/s, v_num=106, train_loss=0.948, Acc%=76.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 938/938 [00:06<00:00, 154.13it/s, v_num=106, train_loss=1.170, Acc%=79.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 938/938 [00:06<00:00, 142.56it/s, v_num=106, train_loss=1.210, Acc%=78.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:07<00:00, 128.11it/s, v_num=106, train_loss=1.190, Acc%=83.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:07<00:00, 127.97it/s, v_num=106, train_loss=1.190, Acc%=83.20]\n"
     ]
    }
   ],
   "source": [
    "model = OptuDrop()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "routine = ClassificationRoutine(\n",
    "    model=model,\n",
    "    num_classes=datamodule.num_classes,\n",
    "    loss=loss_fn,\n",
    "    optim_recipe=optim_optunet(model),\n",
    "    is_ensemble=False\n",
    ")\n",
    "\n",
    "trainer = TUTrainer(\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    max_epochs=EPOCHS\n",
    ")\n",
    "\n",
    "trainer.fit(model=routine, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 88.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">      Classification       </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     Acc      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          83.21%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Brier     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.26384          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   Entropy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.81296          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     NLL      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.56206          </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">        Calibration        </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     ECE      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.10622          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     aECE     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.10622          </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\"> Selective Classification  </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    AUGRC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           3.50%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     AURC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           4.51%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Cov@5Risk   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          65.15%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Risk@80Cov  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           8.86%           </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Classification      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    Acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         83.21%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Brier    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.26384         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  Entropy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.81296         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    NLL     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.56206         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Calibration       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    ECE     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.10622         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    aECE    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.10622         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSelective Classification \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   AUGRC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          3.50%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    AURC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          4.51%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Cov@5Risk  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         65.15%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Risk@80Cov \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          8.86%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "results = trainer.test(model=routine, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viBNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SWAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model            | OptuNet          | 392    | train\n",
      "1 | loss             | CrossEntropyLoss | 0      | train\n",
      "2 | format_batch_fn  | Identity         | 0      | train\n",
      "3 | val_cls_metrics  | MetricCollection | 0      | train\n",
      "4 | test_cls_metrics | MetricCollection | 0      | train\n",
      "5 | test_id_entropy  | Entropy          | 0      | train\n",
      "6 | mixup            | Identity         | 0      | train\n",
      "--------------------------------------------------------------\n",
      "392       Trainable params\n",
      "0         Non-trainable params\n",
      "392       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 938/938 [00:10<00:00, 89.24it/s, v_num=110, train_loss=2.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [00:05<00:00, 163.87it/s, v_num=110, train_loss=1.550, Acc%=19.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [00:06<00:00, 143.22it/s, v_num=110, train_loss=1.560, Acc%=47.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 938/938 [00:06<00:00, 156.00it/s, v_num=110, train_loss=0.687, Acc%=70.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 938/938 [00:06<00:00, 153.72it/s, v_num=110, train_loss=0.852, Acc%=71.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [00:06<00:00, 148.31it/s, v_num=110, train_loss=0.868, Acc%=71.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 938/938 [00:06<00:00, 142.90it/s, v_num=110, train_loss=0.647, Acc%=79.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 938/938 [00:07<00:00, 126.76it/s, v_num=110, train_loss=1.140, Acc%=78.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 938/938 [00:07<00:00, 128.91it/s, v_num=110, train_loss=0.784, Acc%=78.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 938/938 [00:06<00:00, 144.44it/s, v_num=110, train_loss=1.130, Acc%=77.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 938/938 [00:06<00:00, 144.13it/s, v_num=110, train_loss=1.150, Acc%=76.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 938/938 [00:06<00:00, 144.36it/s, v_num=110, train_loss=0.975, Acc%=74.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 938/938 [00:06<00:00, 142.73it/s, v_num=110, train_loss=1.030, Acc%=68.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 938/938 [00:06<00:00, 136.00it/s, v_num=110, train_loss=1.100, Acc%=79.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:07<00:00, 133.25it/s, v_num=110, train_loss=0.944, Acc%=79.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:07<00:00, 133.12it/s, v_num=110, train_loss=0.944, Acc%=79.70]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = OptuNet()\n",
    "\n",
    "# Define SWAG model, using the number of samples to approximate the posterior\n",
    "swag_model = TUSWAG(model, cycle_start=20, cycle_length=10)  # Set the number of samples for SWAG\n",
    "# Set up optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Set up the ClassificationRoutine\n",
    "routine = ClassificationRoutine(model,\n",
    "                                num_classes=datamodule.num_classes,\n",
    "                                loss=nn.CrossEntropyLoss(), \n",
    "                                optim_recipe=optim_optunet(model),\n",
    "                                is_ensemble=False)\n",
    "\n",
    "# Instantiate the trainer with the routine\n",
    "trainer = TUTrainer(accelerator=\"gpu\", max_epochs=EPOCHS, enable_progress_bar=True)\n",
    "\n",
    "# Start the training process\n",
    "trainer.fit(model=routine, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 96.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">      Classification       </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     Acc      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          79.67%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Brier     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.29377          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   Entropy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.69210          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     NLL      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.63778          </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">        Calibration        </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     ECE      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.03635          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     aECE     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.03515          </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\"> Selective Classification  </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    AUGRC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           4.63%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     AURC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           5.97%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Cov@5Risk   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          56.69%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Risk@80Cov  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          12.21%           </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Classification      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    Acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         79.67%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Brier    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.29377         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  Entropy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.69210         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    NLL     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.63778         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Calibration       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    ECE     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.03635         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    aECE    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.03515         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSelective Classification \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   AUGRC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          4.63%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    AURC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          5.97%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Cov@5Risk  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         56.69%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Risk@80Cov \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         12.21%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/cal/ECE': 0.03635436296463013,\n",
       "  'test/cal/aECE': 0.035149142146110535,\n",
       "  'test/cls/Acc': 0.7967000007629395,\n",
       "  'test/cls/Brier': 0.29376837611198425,\n",
       "  'test/cls/NLL': 0.6377840638160706,\n",
       "  'test/sc/AUGRC': 0.04629536718130112,\n",
       "  'test/sc/AURC': 0.059700217097997665,\n",
       "  'test/sc/Cov@5Risk': 0.5669000148773193,\n",
       "  'test/sc/Risk@80Cov': 0.12212499976158142,\n",
       "  'test/cls/Entropy': 0.6921000480651855}]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=routine, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in datamodule.test_dataloader()[0]:\n",
    "        output = swag_model(data)\n",
    "        preds = output.argmax(dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(target)\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels.numpy(), all_preds.numpy())\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model            | OptuNet          | 392    | train\n",
      "1 | loss             | CrossEntropyLoss | 0      | train\n",
      "2 | format_batch_fn  | Identity         | 0      | train\n",
      "3 | val_cls_metrics  | MetricCollection | 0      | train\n",
      "4 | test_cls_metrics | MetricCollection | 0      | train\n",
      "5 | test_id_entropy  | Entropy          | 0      | train\n",
      "6 | mixup            | Identity         | 0      | train\n",
      "--------------------------------------------------------------\n",
      "392       Trainable params\n",
      "0         Non-trainable params\n",
      "392       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 938/938 [00:09<00:00, 98.00it/s, v_num=111, train_loss=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [00:05<00:00, 163.53it/s, v_num=111, train_loss=1.570, Acc%=40.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [00:06<00:00, 148.50it/s, v_num=111, train_loss=1.060, Acc%=51.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 938/938 [00:07<00:00, 126.88it/s, v_num=111, train_loss=1.060, Acc%=59.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 938/938 [00:06<00:00, 155.34it/s, v_num=111, train_loss=1.360, Acc%=65.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [00:06<00:00, 146.63it/s, v_num=111, train_loss=1.070, Acc%=65.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 938/938 [00:06<00:00, 154.08it/s, v_num=111, train_loss=1.150, Acc%=62.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 938/938 [00:06<00:00, 153.33it/s, v_num=111, train_loss=1.010, Acc%=62.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 938/938 [00:06<00:00, 150.81it/s, v_num=111, train_loss=1.250, Acc%=66.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 938/938 [00:05<00:00, 157.10it/s, v_num=111, train_loss=1.290, Acc%=70.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 938/938 [00:06<00:00, 151.55it/s, v_num=111, train_loss=1.180, Acc%=71.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 938/938 [00:06<00:00, 152.28it/s, v_num=111, train_loss=1.310, Acc%=71.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 938/938 [00:06<00:00, 151.89it/s, v_num=111, train_loss=1.130, Acc%=73.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 938/938 [00:06<00:00, 139.59it/s, v_num=111, train_loss=0.788, Acc%=71.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 938/938 [00:06<00:00, 143.90it/s, v_num=111, train_loss=0.957, Acc%=75.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 938/938 [00:06<00:00, 152.56it/s, v_num=111, train_loss=0.793, Acc%=75.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 938/938 [00:06<00:00, 150.52it/s, v_num=111, train_loss=0.925, Acc%=73.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 938/938 [00:06<00:00, 154.15it/s, v_num=111, train_loss=0.819, Acc%=74.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 938/938 [00:05<00:00, 158.87it/s, v_num=111, train_loss=0.597, Acc%=74.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 938/938 [00:05<00:00, 158.12it/s, v_num=111, train_loss=0.736, Acc%=75.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 938/938 [00:06<00:00, 153.78it/s, v_num=111, train_loss=0.776, Acc%=76.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 938/938 [00:05<00:00, 157.26it/s, v_num=111, train_loss=0.687, Acc%=76.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 938/938 [00:06<00:00, 151.80it/s, v_num=111, train_loss=0.602, Acc%=72.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 938/938 [00:06<00:00, 150.79it/s, v_num=111, train_loss=0.942, Acc%=76.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 938/938 [00:05<00:00, 157.47it/s, v_num=111, train_loss=0.862, Acc%=74.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 938/938 [00:06<00:00, 154.81it/s, v_num=111, train_loss=1.180, Acc%=76.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 938/938 [00:06<00:00, 153.44it/s, v_num=111, train_loss=1.600, Acc%=75.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 938/938 [00:06<00:00, 152.66it/s, v_num=111, train_loss=1.180, Acc%=77.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 938/938 [00:06<00:00, 152.92it/s, v_num=111, train_loss=1.200, Acc%=76.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 938/938 [00:05<00:00, 156.67it/s, v_num=111, train_loss=0.617, Acc%=75.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 938/938 [00:06<00:00, 144.65it/s, v_num=111, train_loss=1.210, Acc%=75.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 938/938 [00:06<00:00, 148.81it/s, v_num=111, train_loss=0.837, Acc%=75.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 938/938 [00:06<00:00, 146.23it/s, v_num=111, train_loss=1.410, Acc%=77.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 938/938 [00:06<00:00, 136.56it/s, v_num=111, train_loss=0.536, Acc%=76.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 938/938 [00:06<00:00, 146.90it/s, v_num=111, train_loss=0.813, Acc%=77.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 938/938 [00:06<00:00, 152.77it/s, v_num=111, train_loss=0.887, Acc%=77.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 938/938 [00:06<00:00, 145.62it/s, v_num=111, train_loss=0.781, Acc%=77.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 938/938 [00:06<00:00, 134.45it/s, v_num=111, train_loss=0.650, Acc%=77.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 938/938 [00:07<00:00, 126.57it/s, v_num=111, train_loss=0.866, Acc%=77.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 938/938 [00:06<00:00, 147.64it/s, v_num=111, train_loss=1.100, Acc%=77.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 938/938 [00:05<00:00, 159.41it/s, v_num=111, train_loss=0.762, Acc%=78.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 938/938 [00:05<00:00, 156.69it/s, v_num=111, train_loss=0.779, Acc%=75.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 938/938 [00:06<00:00, 140.07it/s, v_num=111, train_loss=1.180, Acc%=77.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 938/938 [00:06<00:00, 139.94it/s, v_num=111, train_loss=0.852, Acc%=75.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 938/938 [00:06<00:00, 138.22it/s, v_num=111, train_loss=1.190, Acc%=77.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 938/938 [00:06<00:00, 143.15it/s, v_num=111, train_loss=0.915, Acc%=76.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 938/938 [00:06<00:00, 150.63it/s, v_num=111, train_loss=0.921, Acc%=75.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 938/938 [00:06<00:00, 150.21it/s, v_num=111, train_loss=0.806, Acc%=77.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 938/938 [00:06<00:00, 154.64it/s, v_num=111, train_loss=0.798, Acc%=77.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 938/938 [00:06<00:00, 146.48it/s, v_num=111, train_loss=0.626, Acc%=76.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 938/938 [00:06<00:00, 150.42it/s, v_num=111, train_loss=0.702, Acc%=77.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 938/938 [00:06<00:00, 147.36it/s, v_num=111, train_loss=1.090, Acc%=77.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 938/938 [00:06<00:00, 141.51it/s, v_num=111, train_loss=0.914, Acc%=77.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 938/938 [00:06<00:00, 146.21it/s, v_num=111, train_loss=1.080, Acc%=77.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 938/938 [00:06<00:00, 142.31it/s, v_num=111, train_loss=1.000, Acc%=77.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 938/938 [00:06<00:00, 143.81it/s, v_num=111, train_loss=0.917, Acc%=76.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 938/938 [00:06<00:00, 138.98it/s, v_num=111, train_loss=0.645, Acc%=77.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 938/938 [00:06<00:00, 143.60it/s, v_num=111, train_loss=0.672, Acc%=78.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 938/938 [00:06<00:00, 154.10it/s, v_num=111, train_loss=1.070, Acc%=77.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:05<00:00, 162.55it/s, v_num=111, train_loss=0.675, Acc%=78.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:06<00:00, 140.49it/s, v_num=111, train_loss=0.675, Acc%=77.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 938/938 [00:06<00:00, 140.35it/s, v_num=111, train_loss=0.675, Acc%=77.20]\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = OptuNet()\n",
    "\n",
    "def scheduler_laplace(optimizer):\n",
    "    return MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[15, 30],\n",
    "        gamma=0.5\n",
    "    )\n",
    "\n",
    "# Routine\n",
    "loss_fn = nn.CrossEntropyLoss()  # Standard cross-entropy loss\n",
    "routine = ClassificationRoutine(\n",
    "    model=model,\n",
    "    num_classes=datamodule.num_classes,\n",
    "    loss=loss_fn,\n",
    "    optim_recipe=optim_optunet(model),\n",
    "    # scheduler_recipe=scheduler_laplace,\n",
    "    is_ensemble=False\n",
    ")\n",
    "\n",
    "# Train the model to MAP estimate\n",
    "trainer = TUTrainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=EPOCHS,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "trainer.fit(model=routine, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 84.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 83.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">      Classification       </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     Acc      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          77.16%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    Brier     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.33493          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   Entropy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.78877          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     NLL      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.70458          </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">        Calibration        </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     ECE      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.05171          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     aECE     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.05261          </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\"> Selective Classification  </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    AUGRC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           6.09%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     AURC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           8.82%           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Cov@5Risk   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           nan%            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  Risk@80Cov  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          15.06%           </span>│\n",
       "└──────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Classification      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    Acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         77.16%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   Brier    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.33493         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  Entropy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.78877         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    NLL     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.70458         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Calibration       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    ECE     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.05171         \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    aECE    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.05261         \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSelective Classification \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   AUGRC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          6.09%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    AURC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          8.82%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Cov@5Risk  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          nan%           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m Risk@80Cov \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         15.06%          \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/cal/ECE': 0.05171032249927521,\n",
       "  'test/cal/aECE': 0.05260957032442093,\n",
       "  'test/cls/Acc': 0.7716000080108643,\n",
       "  'test/cls/Brier': 0.3349318504333496,\n",
       "  'test/cls/NLL': 0.7045778632164001,\n",
       "  'test/sc/AUGRC': 0.060908034443855286,\n",
       "  'test/sc/AURC': 0.08823738992214203,\n",
       "  'test/sc/Cov@5Risk': nan,\n",
       "  'test/sc/Risk@80Cov': 0.15062500536441803,\n",
       "  'test/cls/Entropy': 0.7887654304504395}]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=routine, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\dev\\school\\DD2412 DLA\\posterior_symmetry_reproduction\\.venv\\Lib\\site-packages\\laplace\\baselaplace.py:435: UserWarning: By default `link_approx` is `probit`. Make sure to set it equals to the way you want to call `la(test_data, pred_type=..., link_approx=...)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply Laplace approximation\n",
    "laplace_model = Laplace(model, likelihood='classification', subset_of_weights='last_layer', hessian_structure='full')\n",
    "laplace_model.fit(datamodule.train_dataloader())  # Fit the Laplace model on training data\n",
    "laplace_model.optimize_prior_precision()  # Optimize prior precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace Model Test Accuracy: 77.16%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Test loop\n",
    "for inputs, targets in datamodule.test_dataloader()[0]:\n",
    "    # Compute predictive distribution using Laplace model\n",
    "    predictive_probs = laplace_model(inputs)  # Returns predictive probabilities\n",
    "    predicted_labels = predictive_probs.argmax(dim=1)\n",
    "\n",
    "    correct += (predicted_labels == targets).sum().item()\n",
    "    total += targets.size(0)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Laplace Model Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGHMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pSGLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_ensemble(model_class, datamodule, num_ensembles=10, save_dir=\"models/deep_ensemble\"):\n",
    "    \"\"\"\n",
    "    Train a deep ensemble of models.\n",
    "    Args:\n",
    "        model_class: The model class (e.g., OptuNet).\n",
    "        datamodule: Data module providing train/val/test splits.\n",
    "        num_ensembles (int): Number of models in the ensemble.\n",
    "        save_dir (str): Directory to save the trained models.\n",
    "    Returns:\n",
    "        list: Trained models.\n",
    "    \"\"\"\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    trained_models = []\n",
    "    for i in range(num_ensembles):\n",
    "        print(f\"Training model {i + 1}/{num_ensembles}...\")\n",
    "        \n",
    "        # Initialize a new model\n",
    "        model = model_class()\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        routine = ClassificationRoutine(\n",
    "            model=model,\n",
    "            num_classes=datamodule.num_classes,\n",
    "            loss=loss_fn,\n",
    "            optim_recipe=optim_optunet(model),  # Replace with appropriate optimizer\n",
    "            is_ensemble=False\n",
    "        )\n",
    "\n",
    "        # Trainer\n",
    "        trainer = TUTrainer(\n",
    "            accelerator=\"gpu\",\n",
    "            max_epochs=EPOCHS,\n",
    "            enable_progress_bar=True\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model=routine, datamodule=datamodule)\n",
    "\n",
    "        # Save the model\n",
    "        model_path = save_path / f\"model_{i+1}.pt\"\n",
    "        trainer.save_checkpoint(model_path)\n",
    "\n",
    "        trained_models.append(model)\n",
    "\n",
    "    return trained_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, dataloader):\n",
    "    \"\"\"\n",
    "    Perform inference using a deep ensemble.\n",
    "    Args:\n",
    "        models (list): List of trained models.\n",
    "        dataloader (DataLoader): DataLoader for test data.\n",
    "    Returns:\n",
    "        np.ndarray: Averaged predictions from the ensemble.\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.cuda()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)  # Logits shape: (batch_size, num_classes)\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "        \n",
    "        all_preds.append(np.concatenate(preds, axis=0))  # Combine batches\n",
    "\n",
    "    # Stack predictions from all models and average\n",
    "    ensemble_preds = np.mean(np.stack(all_preds, axis=0), axis=0)\n",
    "    return ensemble_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_models = train_deep_ensemble(OptuNet, datamodule, num_ensembles=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preds Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_confidence_interval(model, dataloader, confidence=0.95):\n",
    "    # model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            # inputs = inputs.to(DEVICE)\n",
    "            # targets = targets.to(DEVICE)\n",
    "\n",
    "            # For Monte carlo estimation of the ELBO using 3 samples\n",
    "            preds = torch.stack([model(inputs) for _ in range(MC_SAMPLES)], dim=0)\n",
    "\n",
    "            # Calculate mean and standard deviation\n",
    "            preds_mean = preds.mean(dim=0)\n",
    "            preds_std = preds.std(dim=0)\n",
    "\n",
    "            # Apply softmax to the mean predictions for probabilities\n",
    "            preds_mean = F.softmax(preds_mean, dim=1)\n",
    "\n",
    "\n",
    "            # Compute confidence intervals\n",
    "            z_value = st.norm.ppf(1 - (1 - confidence) / 2)  #dynamically computing the z-score for a given confidence level (e.g., 95%, 99%).\n",
    "            ci_lower = preds_mean - z_value * preds_std\n",
    "            ci_upper = preds_mean + z_value * preds_std\n",
    "\n",
    "            all_preds.append(preds_mean)\n",
    "            all_targets.append(targets)\n",
    "            lower_bounds.append(ci_lower)\n",
    "            upper_bounds.append(ci_upper)\n",
    "\n",
    "    # Concatenate results for all batches\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    lower_bounds = torch.cat(lower_bounds)\n",
    "    upper_bounds = torch.cat(upper_bounds)\n",
    "\n",
    "    return all_preds, all_targets, lower_bounds, upper_bounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_sampling(model, data_loader, num_samples=100):\n",
    "    # model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        sampled_preds = []\n",
    "        for inputs, _ in data_loader:\n",
    "            # inputs = inputs.cuda()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                sampled_preds.append(outputs.cpu().numpy())\n",
    "        predictions.append(np.concatenate(sampled_preds, axis=0))\n",
    "\n",
    "    return np.array(predictions) # Shape: (num_samples, num_examples, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_model_predictions(models, data_loader):\n",
    "    all_predictions = []\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for inputs, _ in data_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)  # Logits\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "        all_predictions.append(np.concatenate(preds, axis=0))  # Combine batches\n",
    "\n",
    "    return np.array(all_predictions)  # Shape: (num_models, num_datapoints, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_samples(models):\n",
    "    weight_samples = []\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        weights = []\n",
    "        for param in model.parameters():\n",
    "            weights.append(param.detach().cpu().numpy().flatten())  # Flatten weights\n",
    "        weight_samples.append(np.concatenate(weights))\n",
    "\n",
    "    return np.array(weight_samples)  # Shape: (num_models, num_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_source_samples(model, dataloader, num_samples=N_SAMPLES):\n",
    "    # model.eval()\n",
    "    samples = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        sampled_weights = []\n",
    "        for param in model.parameters():\n",
    "            sampled_weights.append(param.detach().cpu().numpy().flatten())  # Flatten weights\n",
    "        samples.append(np.concatenate(sampled_weights))\n",
    "\n",
    "    return np.array(samples)  # Shape: (num_samples, num_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mmd(model, posterior_models, test_dataset, num_samples=100):\n",
    "    # # Posterior estimation with weights?\n",
    "    # target_weights = generate_target_samples(posterior_models)\n",
    "    # source_weights = generate_source_samples(model, test_dataset, num_samples=num_samples)\n",
    "\n",
    "    # mmd_weights = mmdagg(\n",
    "    #     X=source_weights,\n",
    "    #     Y=target_weights,\n",
    "    #     alpha=0.05,\n",
    "    #     kernel=\"laplace_gaussian\",\n",
    "    #     number_bandwidths=10,\n",
    "    #     weights_type=\"uniform\",\n",
    "    #     B1=2000,\n",
    "    #     B2=2000,\n",
    "    #     B3=50,\n",
    "    #     seed=42424242\n",
    "    # )\n",
    "\n",
    "    # Posterior estimation with predictions?\n",
    "    target_preds = target_model_predictions(posterior_models, test_dataset)\n",
    "    source_preds = monte_carlo_sampling(model, test_dataset, num_samples=num_samples)\n",
    "    target_avg = np.mean(target_preds, axis=1)\n",
    "    source_avg = np.mean(source_preds, axis=1)\n",
    "\n",
    "    mmd_preds = mmdagg(\n",
    "        X=source_avg,\n",
    "        Y=target_avg,\n",
    "        alpha=0.05,\n",
    "        kernel=\"laplace_gaussian\",\n",
    "        number_bandwidths=10,\n",
    "        weights_type=\"uniform\",\n",
    "        B1=2000,\n",
    "        B2=2000,\n",
    "        B3=50,\n",
    "        seed=42424242\n",
    "    )\n",
    "\n",
    "    return None, mmd_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aupr_score(predictions, labels):\n",
    "    n_classes = predictions.shape[1]\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    aupr = {}\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        # Binarize the labels for class i\n",
    "        binary_labels = (labels == i).astype(int)\n",
    "        precision[i], recall[i], _ = precision_recall_curve(binary_labels, predictions[:, i])\n",
    "        aupr[i] = auc(recall[i], precision[i])\n",
    "\n",
    "    # Optional: Aggregate AUPR\n",
    "    mean_aupr = np.mean(list(aupr.values()))\n",
    "    return mean_aupr, aupr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPR95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr95_score(predictions, labels):\n",
    "    # Calculate predicted classes and confidences\n",
    "    predicted_classes = np.argmax(predictions, axis=1)  # Class with highest probability\n",
    "    confidences = np.max(predictions, axis=1)           # Confidence scores (max probability)\n",
    "    binary_labels = (predicted_classes == labels).astype(int) # Determine binary labels (1 for correct, 0 for incorrect)\n",
    "    fpr, tpr, thresholds = roc_curve(binary_labels, confidences)\n",
    "\n",
    "    # Find the threshold where TPR is closest to 95%\n",
    "    idx = np.where(tpr >= 0.95)[0][0]\n",
    "    return fpr[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ace_score(predictions, labels, n_bins=10):\n",
    "    # Convert predictions and labels to numpy arrays\n",
    "    predicted_probs = predictions.cpu().numpy()\n",
    "    true_labels = labels.cpu().numpy()\n",
    "\n",
    "    # One-hot encode true labels for multi-class calibration\n",
    "    num_classes = predicted_probs.shape[1]\n",
    "    true_labels_one_hot = np.eye(num_classes)[true_labels]  # Shape: (num_samples, num_classes)\n",
    "\n",
    "    # Initialize ACE\n",
    "    ace = 0.0\n",
    "\n",
    "    # Loop over each class\n",
    "    for class_idx in range(num_classes):\n",
    "        # Get predicted probabilities and true labels for the current class\n",
    "        prob_pred = predicted_probs[:, class_idx]\n",
    "        prob_true = true_labels_one_hot[:, class_idx]\n",
    "\n",
    "        # Compute calibration curve\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(prob_true, prob_pred, n_bins=n_bins)\n",
    "\n",
    "        # Compute ACE for this class\n",
    "        ace += np.mean(np.abs(fraction_of_positives - mean_predicted_value))\n",
    "\n",
    "    # Average over all classes\n",
    "    ace /= num_classes\n",
    "    return ace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, posterior_models, test_loader):\n",
    "    # model.to(DEVICE)\n",
    "    preds, targets, lower_bounds, upper_bounds = evaluate_confidence_interval(model, test_loader)\n",
    "    predictions = preds.cpu().numpy()\n",
    "    labels = targets.cpu().numpy()\n",
    "\n",
    "    # Scores\n",
    "    mean_aupr, aupr = aupr_score(predictions, labels)\n",
    "    fpr95 = fpr95_score(predictions, labels)\n",
    "    ace = ace_score(preds, targets)\n",
    "    mmd_weights, mmd_preds = calculate_mmd(model, posterior_models, test_loader, num_samples=N_SAMPLES)\n",
    "\n",
    "    print(f\"AUPR: {mean_aupr}\")\n",
    "    print(f\"FPR95: {fpr95}\")\n",
    "    print(f\"ACE: {ace:.4f}\")\n",
    "    print(f\"MMD: {np.sum(mmd_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE score: 0.1539476851886034\n",
      "AUPR: 0.8135783680644151\n",
      "FPR95: 0.7802101576182137\n",
      "ACE: 0.3467\n",
      "ACE2: 0.1539\n",
      "MMD: 13.145983918683527\n"
     ]
    }
   ],
   "source": [
    "score_model(laplace_model, posterior_models, datamodule.test_dataloader()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
