{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtKOd5ZhMT5f"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_uncertainty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L0hO7BlBMbw-",
        "outputId": "d699b04d-1bf3-4bc4-e4c8-73397d261881"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_uncertainty\n",
            "  Downloading torch_uncertainty-0.3.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from torch_uncertainty) (1.0.12)\n",
            "Collecting lightning>=2.0 (from lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: torchvision>=0.16 in /usr/local/lib/python3.10/dist-packages (from torch_uncertainty) (0.20.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from torch_uncertainty) (0.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch_uncertainty) (3.8.0)\n",
            "Requirement already satisfied: rich>=10.2.2 in /usr/local/lib/python3.10/dist-packages (from torch_uncertainty) (13.9.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from torch_uncertainty) (0.13.2)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (2.5.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting bitsandbytes<1.0,>=0.42.0 (from lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting hydra-core<2.0,>=1.2.0 (from lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting jsonargparse<5.0,>=4.27.7 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading jsonargparse-4.34.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting omegaconf<3.0,>=2.2.3 (from lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tensorboardX<3.0,>=2.2 (from lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (1.26.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_uncertainty) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.2.2->torch_uncertainty) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.2.2->torch_uncertainty) (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (1.3.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->torch_uncertainty) (2.2.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->torch_uncertainty) (0.26.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->torch_uncertainty) (0.4.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (3.11.10)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<2.0,>=1.2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]>=2.0->torch_uncertainty) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]>=2.0->torch_uncertainty)\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (75.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.2.2->torch_uncertainty) (0.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->torch_uncertainty) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->torch_uncertainty) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torch_uncertainty) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]>=2.0->torch_uncertainty) (4.25.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->torch_uncertainty) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (1.18.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]>=2.0->torch_uncertainty) (6.4.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning>=2.0->lightning[pytorch-extra]>=2.0->torch_uncertainty) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->torch_uncertainty) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->torch_uncertainty) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->torch_uncertainty) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->torch_uncertainty) (2024.8.30)\n",
            "Downloading torch_uncertainty-0.3.1-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.8/274.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.34.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=0a03471630a3a966efd368dc6a3707c40e7a44a46a95e0aff583a82f16d30968\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, typeshed-client, tensorboardX, omegaconf, lightning-utilities, jsonargparse, hydra-core, torchmetrics, bitsandbytes, pytorch-lightning, lightning, torch_uncertainty\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 bitsandbytes-0.45.0 hydra-core-1.3.2 jsonargparse-4.34.1 lightning-2.4.0 lightning-utilities-0.11.9 omegaconf-2.3.0 pytorch-lightning-2.4.0 tensorboardX-2.6.2.2 torch_uncertainty-0.3.1 torchmetrics-1.6.0 typeshed-client-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "25e5fd31464142f498afde5aa4e9610a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install blitz-bayesian-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4jRNL27qVYq",
        "outputId": "d3f8377f-1da8-44cb-aedb-0f9b9d122fbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting blitz-bayesian-pytorch\n",
            "  Downloading blitz_bayesian_pytorch-0.2.8-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from blitz-bayesian-pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from blitz-bayesian-pytorch) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from blitz-bayesian-pytorch) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from blitz-bayesian-pytorch) (1.5.2)\n",
            "Requirement already satisfied: pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from blitz-bayesian-pytorch) (11.0.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->blitz-bayesian-pytorch) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->blitz-bayesian-pytorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->blitz-bayesian-pytorch) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->blitz-bayesian-pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->blitz-bayesian-pytorch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->blitz-bayesian-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->blitz-bayesian-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->blitz-bayesian-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->blitz-bayesian-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->blitz-bayesian-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->blitz-bayesian-pytorch) (3.0.2)\n",
            "Downloading blitz_bayesian_pytorch-0.2.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blitz-bayesian-pytorch\n",
            "Successfully installed blitz-bayesian-pytorch-0.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYDYGVBDMT5h",
        "outputId": "aa6a7604-0466-43b1-b294-3bec1a2832c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "from torch_uncertainty import TUTrainer\n",
        "from torch_uncertainty.datamodules import MNISTDataModule\n",
        "from torch_uncertainty.losses import ELBOLoss\n",
        "from torch_uncertainty.models.lenet import bayesian_lenet\n",
        "from torch_uncertainty.models import mc_dropout\n",
        "from torch_uncertainty.routines import ClassificationRoutine\n",
        "\n",
        "from blitz.modules import BayesianLinear\n",
        "from blitz.utils import variational_estimator\n",
        "import scipy.stats as st\n",
        "\n",
        "from pathlib import Path\n",
        "from safetensors.torch import load_file\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()  # Unmount Google Drive\n",
        "drive.mount('/content/drive')  # Remount Google Drive\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR4kYKQxMT5j"
      },
      "source": [
        "# OptuNet Posterior Approximation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YotA4Fz9MT5k"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DATA_PATH = \"data\"\n",
        "\n",
        "# Parameters from paper\n",
        "EPOCHS = 60\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.04\n",
        "#WEIGHT_DECAY = 2e-4\n",
        "\n",
        "NUM_WORKERS = 4\n",
        "## OptuNet params\n",
        "DROPOUT_RATE = 0.2 # last layer dropout rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDOfBEOUMT5k"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt64ScFBMT5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "08049c9e-8be2-44f9-cb30-b1de6d389859"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MNISTDataModule.__init__() got an unexpected keyword argument 'download'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-50a599b7b50b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#datamodule = MNISTDataModule(root=root, batch_size=BATCH_SIZE, eval_ood=False, num_workers=NUM_WORKERS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdatamodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNISTDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ood\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: MNISTDataModule.__init__() got an unexpected keyword argument 'download'"
          ]
        }
      ],
      "source": [
        "# Load MNIST data\n",
        "root = Path(DATA_PATH)\n",
        "datamodule = MNISTDataModule(root=root, batch_size=BATCH_SIZE, eval_ood=False, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBHRG-HBMT5l"
      },
      "source": [
        "## OptuNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ziMg5hDRMT5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "714dd778-a69d-4c2f-d47b-7725ab9ab142"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef load_optunet_model(version: int):\\n    #Load the model corresponding to the given version.\\n    model = OptuNet(num_classes=datamodule.num_classes)\\n    #path = Path(f\"models/mnist-optunet-0-8191/version_{version}.safetensors\")\\n    #notebook_dir = Path(\"/content/drive/MyDrive/DL,\\\\ adv/project\")\\n    path = \"/content/drive/MyDrive/DL, adv/project/mnist-optunet-0-8191/version_1000.safetensors\"\\n\\n    print(os.path.exists(path))\\n\\n    if not os.path.exists(path):\\n        raise ValueError(\"File does not exist\")\\n\\n    state_dict = load_file(path)\\n\\n    model.load_state_dict(state_dict=state_dict)\\n    return model\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# the variational_estimator decorator adjusts the model to compute and optimize\n",
        "# the Evidence Lower Bound (ELBO)\n",
        "@variational_estimator\n",
        "class OptuNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        # Add layers for OptuNet (use Section C.2.1 from the paper for details)\n",
        "        # Layers: Conv2D (out_ch=2, ks=4, groups=1) -> Max Pooling (ks=3, stride=3) -> ReLU -> Conv2D (out_ch=10, ks=5, groups=2) -> Average Pooling -> ReLU -> Linear 10x10\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=4, groups=1, bias=False)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=10, kernel_size=5, groups=2, bias=False)\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(in_features=10, out_features=10)\n",
        "        #self.fc1 = nn.Linear(in_features=10 * 2 * 2, out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.pool1(self.conv1(x)))  # First conv, max pooling, ReLU\n",
        "        x = self.relu(self.pool2(self.conv2(x)))  # Second conv, avg pooling, ReLU\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        x = self.fc1(x)  # Linear layer\n",
        "        return x\n",
        "\"\"\"\n",
        "def load_optunet_model(version: int):\n",
        "    #Load the model corresponding to the given version.\n",
        "    model = OptuNet(num_classes=datamodule.num_classes)\n",
        "    #path = Path(f\"models/mnist-optunet-0-8191/version_{version}.safetensors\")\n",
        "    #notebook_dir = Path(\"/content/drive/MyDrive/DL,\\ adv/project\")\n",
        "    path = \"/content/drive/MyDrive/DL, adv/project/mnist-optunet-0-8191/version_1000.safetensors\"\n",
        "\n",
        "    print(os.path.exists(path))\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        raise ValueError(\"File does not exist\")\n",
        "\n",
        "    state_dict = load_file(path)\n",
        "\n",
        "    model.load_state_dict(state_dict=state_dict)\n",
        "    return model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#file_path = \"/content/drive/MyDrive/DL, adv/project/mnist-optunet-0-8191/version_1000.safetensors\"\n",
        "#print(\"File exists:\", os.path.exists(file_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCwoVenPQ-ZX",
        "outputId": "cf016422-bfa3-4471-d2ca-a8c4def45f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyketucyMT5n"
      },
      "source": [
        "## Train / Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomClassificationRoutine(ClassificationRoutine):\n",
        "    def __init__(self, lr_scheduler, num_samples, kl_weight, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "        #self.epoch_outputs = []  # Store outputs here if needed\n",
        "        self.num_samples = num_samples\n",
        "        self.kl_weight = kl_weight\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        output = super().training_step(batch, batch_idx)\n",
        "        self.epoch_outputs.append(output)  # Collect outputs manually\n",
        "        return output\n",
        "        \"\"\"\n",
        "\n",
        "        inputs, targets = batch\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        # Calculate ELBO using sample_elbo\n",
        "        elbo = self.model.sample_elbo(\n",
        "            inputs=inputs,\n",
        "            labels=targets,\n",
        "            criterion=nn.CrossEntropyLoss(),\n",
        "            sample_nbr=self.num_samples,\n",
        "            complexity_cost_weight=self.kl_weight\n",
        "        )\n",
        "\n",
        "        self.log(\"train_elbo\", elbo)\n",
        "        return elbo\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # Step the scheduler if it exists\n",
        "        if self.lr_scheduler:\n",
        "            self.lr_scheduler.step()\n",
        "\n",
        "        # Optionally, process self.epoch_outputs here\n",
        "        #self.epoch_outputs.clear()  # Clear outputs for the next epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "87tzD8ymTFOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sNI_9ELMMT5n",
        "outputId": "cc7c82e3-999d-4376-f81e-50d8bb562d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name             | Type             | Params | Mode \n",
            "--------------------------------------------------------------\n",
            "0 | model            | OptuNet          | 392    | train\n",
            "1 | format_batch_fn  | Identity         | 0      | train\n",
            "2 | val_cls_metrics  | MetricCollection | 0      | train\n",
            "3 | test_cls_metrics | MetricCollection | 0      | train\n",
            "4 | test_id_entropy  | Entropy          | 0      | train\n",
            "5 | mixup            | Identity         | 0      | train\n",
            "--------------------------------------------------------------\n",
            "392       Trainable params\n",
            "0         Non-trainable params\n",
            "392       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "30        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name             | Type             | Params | Mode \n",
            "--------------------------------------------------------------\n",
            "0 | model            | OptuNet          | 392    | train\n",
            "1 | format_batch_fn  | Identity         | 0      | train\n",
            "2 | val_cls_metrics  | MetricCollection | 0      | train\n",
            "3 | test_cls_metrics | MetricCollection | 0      | train\n",
            "4 | test_id_entropy  | Entropy          | 0      | train\n",
            "5 | mixup            | Identity         | 0      | train\n",
            "--------------------------------------------------------------\n",
            "392       Trainable params\n",
            "0         Non-trainable params\n",
            "392       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "30        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Classification      \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m    Acc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         82.38%          \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   Brier    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.26314         \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  Entropy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.68393         \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    NLL     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.55140         \u001b[0m\u001b[35m \u001b[0m│\n",
              "└──────────────┴───────────────────────────┘\n",
              "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Calibration       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m    ECE     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.05699         \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    aECE    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         0.05695         \u001b[0m\u001b[35m \u001b[0m│\n",
              "└──────────────┴───────────────────────────┘\n",
              "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTest metric \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSelective Classification \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m   AUGRC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          3.97%          \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    AURC    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          5.35%          \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m Cov@5Risk  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m         59.82%          \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m Risk@80Cov \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          9.81%          \u001b[0m\u001b[35m \u001b[0m│\n",
              "└──────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">      Classification       </span>┃\n",
              "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     Acc      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          82.38%           </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    Brier     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.26314          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   Entropy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.68393          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     NLL      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.55140          </span>│\n",
              "└──────────────┴───────────────────────────┘\n",
              "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\">        Calibration        </span>┃\n",
              "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     ECE      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.05699          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     aECE     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.05695          </span>│\n",
              "└──────────────┴───────────────────────────┘\n",
              "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Test metric  </span>┃<span style=\"font-weight: bold\"> Selective Classification  </span>┃\n",
              "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    AUGRC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           3.97%           </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     AURC     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           5.35%           </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">  Cov@5Risk   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          59.82%           </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">  Risk@80Cov  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           9.81%           </span>│\n",
              "└──────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def optim_lenet(model: nn.Module):\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=0.04\n",
        "    )\n",
        "    return optimizer\n",
        "\n",
        "#trainer = TUTrainer(accelerator=\"gpu\", enable_progress_bar=False, max_epochs=60)\n",
        "trainer = TUTrainer(accelerator=\"cpu\", enable_progress_bar=False, max_epochs=60)\n",
        "\n",
        "# model\n",
        "#model = load_optunet_model(version=1000)\n",
        "model = OptuNet(num_classes=datamodule.num_classes)\n",
        "\n",
        "# loss\n",
        "\"\"\"\n",
        "loss = ELBOLoss(\n",
        "    model=model,\n",
        "    inner_loss=nn.CrossEntropyLoss(),\n",
        "    kl_weight=1 / 10000,\n",
        "    num_samples=3,\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# learning rate scheduler to  decay\n",
        "#the learning rate twice during training, at epochs 15 and 30, dividing the learning rate by 2.\n",
        "def scheduler_lenet(optimizer):\n",
        "    scheduler = MultiStepLR(\n",
        "        optimizer,\n",
        "        milestones=[15, 30],  # Epochs at which to decay the learning rate\n",
        "        gamma=0.5,            # Factor by which to multiply the learning rate\n",
        "    )\n",
        "    return scheduler\n",
        "\n",
        "optimizer = optim_lenet(model)\n",
        "scheduler = scheduler_lenet(optimizer)\n",
        "\n",
        "routine = CustomClassificationRoutine(\n",
        "    model=model,\n",
        "    num_classes=datamodule.num_classes,\n",
        "    loss=None, # computed by sample_elbo in training_step()\n",
        "    optim_recipe=optimizer,\n",
        "    lr_scheduler=scheduler,\n",
        "    num_samples = 3,\n",
        "    kl_weight=1/100000\n",
        "    #is_ensemble=True\n",
        ")\n",
        "\n",
        "trainer.fit(model=routine, datamodule=datamodule)\n",
        "results = trainer.test(model=routine, datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save state dictionary on drive (model parameters)\n",
        "model_path = \"/content/drive/MyDrive/optunet_trained_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0N6D3zOrceu",
        "outputId": "ac6abad6-b282-4581-b7d8-cdb6a5aff0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/optunet_trained_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence Interval Evaluation Function\n",
        "* Sample predictions from your Bayesian model (OptuNet) 3 times for each input.\n",
        "* Calculate the mean and standard deviation of these predictions.\n",
        "* Use these statistics to construct a confidence interval, assuming a Gaussian distribution.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RhYmLJaHxBcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate_confidence_interval(model, dataloader, confidence=0.95):\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    lower_bounds = []\n",
        "    upper_bounds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "\n",
        "            # For Monte carlo estimation of the ELBO using 3 samples\n",
        "            preds = torch.stack([model(inputs) for _ in range(3)], dim=0)\n",
        "\n",
        "            # Calculate mean and standard deviation\n",
        "            preds_mean = preds.mean(dim=0)\n",
        "            preds_std = preds.std(dim=0)\n",
        "\n",
        "            # Apply softmax to the mean predictions for probabilities\n",
        "            preds_mean = F.softmax(preds_mean, dim=1)\n",
        "\n",
        "\n",
        "            # Compute confidence intervals\n",
        "            z_value = st.norm.ppf(1 - (1 - confidence) / 2)  #dynamically computing the z-score for a given confidence level (e.g., 95%, 99%).\n",
        "            ci_lower = preds_mean - z_value * preds_std\n",
        "            ci_upper = preds_mean + z_value * preds_std\n",
        "\n",
        "            all_preds.append(preds_mean)\n",
        "            all_targets.append(targets)\n",
        "            lower_bounds.append(ci_lower)\n",
        "            upper_bounds.append(ci_upper)\n",
        "\n",
        "    # Concatenate results for all batches\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "    lower_bounds = torch.cat(lower_bounds)\n",
        "    upper_bounds = torch.cat(upper_bounds)\n",
        "\n",
        "    return all_preds, all_targets, lower_bounds, upper_bounds\n"
      ],
      "metadata": {
        "id": "mL-Uidnf1Lfw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DATA_PATH = \"data\"\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 4"
      ],
      "metadata": {
        "id": "O7_jgICHukeZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset to the specified path\n",
        "MNIST(root=DATA_PATH, train=True, download=True)\n",
        "MNIST(root=DATA_PATH, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ayWkIYurcE",
        "outputId": "54631f04-2074-4251-ae2c-4971575b8446"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datamodule = MNISTDataModule(\n",
        "    root=Path(DATA_PATH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    eval_ood=False,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n"
      ],
      "metadata": {
        "id": "PO21T8csvOwE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "vgYc6mrSzhO6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datamodule.setup(stage='test')\n",
        "test_dataset = datamodule.test  # Ensure `self.test` exists and is initialized correctly.\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        ")\n"
      ],
      "metadata": {
        "id": "0qGYeQ3cylCX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in test_dataloader:\n",
        "    print(f\"Inputs shape: {inputs.shape}\")\n",
        "    print(f\"Targets shape: {targets.shape}\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx6TU8s4ypmd",
        "outputId": "a7e43c2f-0ba7-458f-957e-8e1edd36a099"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs shape: torch.Size([64, 1, 28, 28])\n",
            "Targets shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(reinitializing the optunet architecture)\n",
        "model = OptuNet(num_classes=datamodule.num_classes)\n",
        "#load state dictionary\n",
        "model_path = \"/content/drive/MyDrive/optunet_trained_model.pth\"\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(DEVICE)  # Send model to appropriate device\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPffa_yorhAl",
        "outputId": "8e6693bb-e597-44b5-84e7-22b74d6a0e5f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-672cce5e43d7>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "preds, targets, lower_bounds, upper_bounds = evaluate_confidence_interval(model, test_dataloader, confidence=0.95)"
      ],
      "metadata": {
        "id": "H1MAI2Y_fRo-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Meo66H5FMT5o"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fCYyuhBMT5o"
      },
      "source": [
        "### AUPR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.metrics import roc_curve"
      ],
      "metadata": {
        "id": "K9BGYMOesTBz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8VIscy__MT5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc95f51-2413-4ddd-d49b-9f6a2f564759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPR for class 1: 0.9828197600748013\n"
          ]
        }
      ],
      "source": [
        "\n",
        "probs = torch.softmax(preds, dim=1)[:, 1].cpu().numpy()  # Adjust for binary classification\n",
        "true_labels = targets.cpu().numpy()\n",
        "# Extract probabilities and true labels\n",
        "probs = torch.softmax(preds, dim=1)[:, positive_class].cpu().numpy()  # Probability of the positive class\n",
        "binary_labels = (true_labels == positive_class).astype(int)  # Binarized labels\n",
        "\n",
        "# Precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(binary_labels, probs)\n",
        "aupr = auc(recall, precision)\n",
        "print(f\"AUPR for class {positive_class}: {aupr}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfgdNCrmMT5p"
      },
      "source": [
        "### FPR95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vCyWN_UtMT5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d93566-dba6-405a-fe34-7db01f26ac7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at TPR=0.95: 0.011844331641285956\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(binary_labels, probs)\n",
        "# Find the threshold where TPR is closest to 0.95\n",
        "tpr_95_index = (tpr >= 0.95).argmax()\n",
        "# FPR at TPR = 0.95\n",
        "fpr_95 = fpr[tpr_95_index]\n",
        "print(f\"FPR at TPR=0.95: {fpr_95}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqD936gDMT5p"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XbChOs4nflKq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mRc2DmPAMT5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c477c10c-57af-4c8a-874e-81c1a4b78052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.38%\n"
          ]
        }
      ],
      "source": [
        "#For Multi-Class Classification\n",
        "# Assuming `preds` are raw outputs from the model, and `targets` are the true labels\n",
        "_, predicted_labels = torch.max(preds, 1)  # Get the index of the max log-probability\n",
        "correct = (predicted_labels == targets).sum().item()  # Count correct predictions\n",
        "accuracy = correct / targets.size(0)  # Calculate accuracy as a ratio\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "def calculate_ace(preds, targets, num_bins=10):\n",
        "    # Convert predictions to probabilities\n",
        "    probs = torch.softmax(preds, dim=1).cpu().numpy()  # For multi-class, probs[:, 1] for class 1, or probs[:, positive_class] for specific class\n",
        "    true_labels = targets.cpu().numpy()\n",
        "\n",
        "    # For binary classification, you can use probs[:, 1] for class 1 (positive_class)\n",
        "    prob_true = probs[:, positive_class]\n",
        "\n",
        "    binary_labels = (true_labels == positive_class).astype(int)\n",
        "\n",
        "    # Get calibration curve: This will return the true fraction of positives and predicted probabilities for each bin\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(binary_labels, prob_true, n_bins=num_bins)\n",
        "\n",
        "    # Calculate ACE: This is the average absolute difference between the true fraction of positives and the predicted probability\n",
        "    ace = np.mean(np.abs(fraction_of_positives - mean_predicted_value))\n",
        "    return ace\n",
        "\n",
        "# Example usage\n",
        "ace = calculate_ace(preds, targets)\n",
        "print(f\"Average Calibration Error (ACE): {ace:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTDWmI806aXJ",
        "outputId": "8ab5cdc0-0fbe-4934-c16e-e366fa544335"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Calibration Error (ACE): 0.4780\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}